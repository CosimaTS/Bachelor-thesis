# Import libraries
import numpy
from keras.datasets import imdb
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
from sklearn.model_selection import train_test_split, GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier 
from sklearn.metrics import brier_score_loss, roc_auc_score, accuracy_score

# Random seed for reproducibility
seed = 7
numpy.random.seed(seed)

##### DATA SET #####
# Load the data set 
top_words = 5000 #input dimension for embedding layer (size of vocabulary)
print("Loading data set ...")
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)
print("Data set loaded!")

X = numpy.concatenate((X_train, X_test), axis=0)#[0:1000] 
y = numpy.concatenate((y_train, y_test), axis=0)#[0:1000]

# Split the data set: 60% Training, 20% Validation, 20% Testing 
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.2, 
                                                    random_state=1)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, 
                                                   test_size=0.25, 
                                                   random_state=1)

print("Size of Training data: ")
print(X_train.shape)
print("Size of Validation data: ")
print(X_val.shape)
print("Size of Testing data: ")
print(X_test.shape)
    
# Truncate and pad input sequences
max_review_length = 350 #input length for embedding layer (length of input sequences)
X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)
X_val = sequence.pad_sequences(X_val, maxlen=max_review_length)
X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)
print("Data padded!")

##### MODEL #####
# Create the model
embedding_vector_length = 32 #output dimension (size of the vector space in which words will be embedded)

def create_model(dropout_rate=0.0):
    model = Sequential()
    model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))
    model.add(Dropout(dropout_rate)) 
    model.add(LSTM(120)) 
    model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation="sigmoid"))
    model.compile(loss="binary_crossentropy", optimizer="Adam", metrics=["accuracy"])
    print(model.summary())
    return model
    
# 3-fold Cross-Validation
model = KerasClassifier(build_fn=create_model, verbose=0)
dropout_rate = [0.1, 0.2]
batch_size = [128, 256]
epochs = [2, 3]
param_grid = dict(dropout_rate=dropout_rate, batch_size=batch_size, epochs=epochs)
grid = GridSearchCV(estimator=model, param_grid = param_grid)
grid_result = grid.fit(X_train, y_train)
print(grid)
print(grid_result.best_score_)  
print(grid_result.best_params_["dropout_rate"])
print(grid_result.best_params_["batch_size"])
print(grid_result.best_params_["epochs"])

model.fit(X_train, y_train, 
          epochs=grid_result.best_params_["epochs"], 
          batch_size=grid_result.best_params_["batch_size"],
          validation_data=(X_val, y_val))
     
##### EVALUATION #####    
# Evaluation of the model
predictions = model.predict_proba(X_test)[:,1]
predictions_label = model.predict(X_test)
lstm_brierscore = brier_score_loss(y_test, predictions)
lstm_rocauc = roc_auc_score(y_test, predictions)
lstm_accuracy = accuracy_score(y_test, predictions_label)

print("Accuracy: ")
print(lstm_accuracy)
print("Brier score: ")
print(lstm_brierscore)
print("AUC score: ")
print(lstm_rocauc)

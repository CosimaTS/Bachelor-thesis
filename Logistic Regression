#### Logistic Regression ####

# Import necessary libraries
import numpy
from time import time
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from keras.datasets import imdb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import brier_score_loss, roc_auc_score

# Calculate the Tf-Idf for training and testing 
def tfidf(X_train, X_test):
    tf_transformer = TfidfVectorizer()
    X_train_tfidf = tf_transformer.fit_transform(X_train)
    X_test_tfidf = tf_transformer.transform(X_test)
    return [X_train_tfidf, X_test_tfidf]

# Create the model: Logistic Regression Classifier
def log_reg_clf(X_train, y_train, X_test, y_test):
    Cs = numpy.array([0.1, 1.0, 5.0, 10.0])
    start = time()
    logreg = LogisticRegression() 
    
    # Parameter tuning: 3-fold Cross-Validation 
    grid = GridSearchCV(estimator = logreg, param_grid = dict(C = Cs))
    grid.fit(X_train, y_train)
    print(grid)
    print(grid.best_score_) #66% von 80% trainiert, 33% von 80% validiert 
    print(grid.best_estimator_.C)
    
    # Train and test the model
    print("Training ...")
    logreg = LogisticRegression(C = grid.best_estimator_.C) 
    logreg.fit(X_train, y_train)
    print("Training done!")

    print("Testing ...")
    logreg_accuracy = logreg.score(X_test, y_test) * 100
    predictions = logreg.predict_proba(X_test)[:,1]
    print(predictions)
    logreg_brierscore = brier_score_loss(y_test, predictions)
    logreg_rocauc = roc_auc_score(y_test, predictions)
    print("Testing done!")
    end = time()
    return [logreg, round(logreg_accuracy, 2), logreg_brierscore, logreg_rocauc, str(round((end - start), 2))]

# Load the data set
print("Loading data set ...")
(X_train, y_train), (X_test, y_test) = imdb.load_data()
print("Data set loaded!")

X = numpy.concatenate((X_train, X_test), axis = 0)
y = numpy.concatenate((y_train, y_test), axis = 0)

# Split data set 
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size = 0.2, 
                                                    random_state = 1)

print("Size of Training data: ")
print(X_train.shape)
print("Size of Testing data: ")
print(X_test.shape)
#print(X_val.shape)

# Create an index
print("Creating the index ...")
word_to_index = imdb.get_word_index()
index_to_word = [None] * (max(word_to_index.values()) + 1)
for w, i in word_to_index.items():
    index_to_word[i] = w
print("Index done!")

# Reconstruct reviews: using the above built index
X_train = [
    ' '.join(
        index_to_word[i]
        for i in X_train[i]
        if i < len(index_to_word)
    ) for i in range(X_train.shape[0])
]

X_test = [
    ' '.join(
        index_to_word[i]
        for i in X_test[i]
        if i < len(index_to_word)
    ) for i in range(X_test.shape[0])
]

X_train, X_test = tfidf(X_train, X_test)

# Run & evaluate the model 
model_fct = log_reg_clf(X_train, y_train, X_test, y_test)
logreg_accuracy = model_fct[1]
logreg_brierscore = model_fct[2]
logreg_rocauc = model_fct[3]
logreg_time = model_fct[4]

print("Accuracy: ")
print(logreg_accuracy)
print("Brier score: ")
print(logreg_brierscore)
print("AUC score: ")
print(logreg_rocauc)
print("Time used to train and test: ")
print(logreg_time)

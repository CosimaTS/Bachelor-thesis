#### LSTM2 (tuned) ####

# Import libraries
import numpy
from keras.datasets import imdb
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
from sklearn.model_selection import train_test_split
from sklearn.metrics import brier_score_loss, roc_auc_score

# Random seed for reproducibility
seed = 7
numpy.random.seed(seed)

##### DATA SET #####
# Load the data set 
top_words = 5000 #input dimension for embedding layer
print("Loading data set ...")
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)
print("Data set loaded!")

X = numpy.concatenate((X_train, X_test), axis=0)
y = numpy.concatenate((y_train, y_test), axis=0)

# Split the data set: 60% Training, 20% Validation, 20% Testing 
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.2, 
                                                    random_state=1)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, 
                                                   test_size=0.25, 
                                                   random_state=1)

print("Size of Training data: ")
print(X_train.shape)
print("Size of Validation data: ")
print(X_val.shape)
print("Size of Testing data: ")
print(X_test.shape)
    
# Truncate and pad input sequences
max_review_length = 500 #input length for embedding layer 
X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)
X_val = sequence.pad_sequences(X_val, maxlen=max_review_length)
X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)
print("Data padded!")

##### MODEL #####
# Create the model
embedding_vector_length = 32 #output dimension 
epochs = 3
batch_size = 256
  
model = Sequential()
model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))
model.add(LSTM(80)) 
model.add(Dense(1, activation="sigmoid"))

# Compile the model
optimizer = "Adam" 
model.compile(loss="binary_crossentropy", optimizer=optimizer, metrics=["accuracy"])
print(model.summary()) #prints a summary of the layers
    
# Fit the model
model.fit(X_train, y_train, 
          epochs=epochs, 
          batch_size=batch_size,
          validation_data=(X_val, y_val))
     
##### EVALUATION #####    
# Evaluation of the model
predictions = model.predict_proba(X_test)[:,0]
lstm_brierscore = brier_score_loss(y_test, predictions)
lstm_rocauc = roc_auc_score(y_test, predictions)
lstm_accuracy = predictions[1]

print("Accuracy: ")
print(lstm_accuracy)
print("Brier score: ")
print(lstm_brierscore)
print("AUC score: ")
print(lstm_rocauc)
